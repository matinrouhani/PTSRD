{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712793f-d61e-428d-ab27-7be1a33bb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import random\n",
    "\n",
    "# ===================  Optimizer Functions =====================\n",
    "# Note: optimizer implementation\n",
    "# Sources: https://github.com/thieu1995/mealpy\n",
    "# https://github.com/Valdecy/pyMetaheuristic\n",
    "\n",
    "# =================== XGBoost & Data Preparation =====================\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load data and prepare train/test splits with scaling.\"\"\"\n",
    "    data = pd.read_excel(file_path)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    \n",
    "    # Apply scaling\n",
    "    scaler_X = PowerTransformer()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        X_scaled, y, data.index, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, train_indices, test_indices, scaler_X\n",
    "\n",
    "def create_objective_function_with_kfold(X_train, y_train, n_splits=5):\n",
    "    \"\"\"Create objective function with K-fold cross-validation for hyperparameter optimization.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    kfold_splits = list(kf.split(X_train))\n",
    "    \n",
    "    def objective_function(params):\n",
    "        learning_rate, n_estimators, max_depth, min_child_weight, subsample, colsample_bytree, colsample_bylevel, alpha, lambda_param = params\n",
    "        \n",
    "        # Convert parameters to appropriate types\n",
    "        max_depth = int(max_depth)\n",
    "        n_estimators = int(n_estimators)\n",
    "        \n",
    "        model_params = {\n",
    "            'learning_rate': learning_rate,\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_child_weight': min_child_weight,\n",
    "            'subsample': subsample,\n",
    "            'colsample_bytree': colsample_bytree,\n",
    "            'colsample_bylevel': colsample_bylevel,\n",
    "            'alpha': alpha,\n",
    "            'lambda': lambda_param,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # Perform K-fold cross-validation\n",
    "        fold_rmse_scores = []\n",
    "        for train_idx, val_idx in kfold_splits:\n",
    "            X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            model = XGBRegressor(**model_params)\n",
    "            model.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_val, y_fold_val)], verbose=False)\n",
    "            y_pred = model.predict(X_fold_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, y_pred))\n",
    "            fold_rmse_scores.append(rmse)\n",
    "        \n",
    "        return np.mean(fold_rmse_scores)\n",
    "    \n",
    "    return objective_function, kfold_splits\n",
    "\n",
    "def optimize_xgboost_hyperparameters(X_train, y_train, iterations=10, population=50, n_splits=5):\n",
    "    \"\"\"Optimize XGBoost hyperparameters using YDSE algorithm with K-fold CV.\"\"\"\n",
    "    \n",
    "    # Define parameter bounds for XGBoost\n",
    "    param_bounds = {\n",
    "        'learning_rate': (0.01, 0.55),\n",
    "        'n_estimators': (100, 300),\n",
    "        'max_depth': (3, 7),\n",
    "        'min_child_weight': (7, 20),\n",
    "        'subsample': (0.6, 0.8),\n",
    "        'colsample_bytree': (0.6, 0.8),\n",
    "        'colsample_bylevel': (0.6, 0.8),\n",
    "        'alpha': (0.5, 1.0),\n",
    "        'lambda': (0.5, 1.0)\n",
    "    }\n",
    "    \n",
    "    param_names = ['learning_rate', 'n_estimators', 'max_depth', 'min_child_weight', \n",
    "                   'subsample', 'colsample_bytree', 'colsample_bylevel', 'alpha', 'lambda']\n",
    "    \n",
    "    lb = [param_bounds[name][0] for name in param_names]\n",
    "    ub = [param_bounds[name][1] for name in param_names]\n",
    "    \n",
    "    # Create objective function with K-fold CV\n",
    "    objective_function, kfold_splits = create_objective_function_with_kfold(X_train, y_train, n_splits)\n",
    "    \n",
    "    # Run YDSE optimization\n",
    "    best_fitness, best_solution, fitness_history = YDSE_algo(\n",
    "        max_iter=iterations,\n",
    "        n=population,\n",
    "        dim=len(param_names),\n",
    "        lb=lb,\n",
    "        ub=ub,\n",
    "        objective_function=objective_function\n",
    "    )\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    best_params = {\n",
    "        'learning_rate': best_solution[0],\n",
    "        'n_estimators': int(best_solution[1]),\n",
    "        'max_depth': int(best_solution[2]),\n",
    "        'min_child_weight': best_solution[3],\n",
    "        'subsample': best_solution[4],\n",
    "        'colsample_bytree': best_solution[5],\n",
    "        'colsample_bylevel': best_solution[6],\n",
    "        'alpha': best_solution[7],\n",
    "        'lambda': best_solution[8],\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbosity': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    return best_params, best_fitness, kfold_splits\n",
    "\n",
    "def evaluate_fold_performance(X_train, y_train, kfold_splits, best_params, train_indices):\n",
    "    \"\"\"Evaluate model performance on individual K-fold splits.\"\"\"\n",
    "    fold_results = {}\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kfold_splits):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Train model on this fold\n",
    "        fold_model = XGBRegressor(**best_params)\n",
    "        fold_model.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_val, y_fold_val)], verbose=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        fold_train_pred = fold_model.predict(X_fold_train)\n",
    "        fold_val_pred = fold_model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_results[f'fold_{fold_idx + 1}'] = {\n",
    "            'train_indices': train_indices[train_idx],\n",
    "            'val_indices': train_indices[val_idx],\n",
    "            'fold_train_pred': fold_train_pred,\n",
    "            'fold_val_pred': fold_val_pred,\n",
    "            'metrics': {\n",
    "                'train_r2': r2_score(y_fold_train, fold_train_pred),\n",
    "                'train_rmse': np.sqrt(mean_squared_error(y_fold_train, fold_train_pred)),\n",
    "                'train_mae': mean_absolute_error(y_fold_train, fold_train_pred),\n",
    "                'val_r2': r2_score(y_fold_val, fold_val_pred),\n",
    "                'val_rmse': np.sqrt(mean_squared_error(y_fold_val, fold_val_pred)),\n",
    "                'val_mae': mean_absolute_error(y_fold_val, fold_val_pred)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, params):\n",
    "    \"\"\"Train XGBoost model with optimized parameters and return metrics.\"\"\"\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_model = XGBRegressor(**params)\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = xgb_model.predict(X_train)\n",
    "    test_predictions = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'train_r2': r2_score(y_train, train_predictions),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, train_predictions)),\n",
    "        'train_mae': mean_absolute_error(y_train, train_predictions),\n",
    "        'test_r2': r2_score(y_test, test_predictions),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, test_predictions)),\n",
    "        'test_mae': mean_absolute_error(y_test, test_predictions)\n",
    "    }\n",
    "    \n",
    "    return xgb_model, metrics\n",
    "\n",
    "def main(file_path=\"P03.xlsx\", iterations=10, population=50, n_splits=5):\n",
    "    \"\"\"Main function to run XGBoost optimization with YDSE and K-fold CV.\"\"\"\n",
    "    \n",
    "    # Load and prepare data\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices, scaler = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Optimize hyperparameters with K-fold CV\n",
    "    best_params, best_fitness, kfold_splits = optimize_xgboost_hyperparameters(\n",
    "        X_train, y_train, iterations, population, n_splits\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate final model\n",
    "    model, metrics = train_and_evaluate_model(X_train, X_test, y_train, y_test, best_params)\n",
    "    \n",
    "    # Evaluate individual fold performance\n",
    "    fold_results = evaluate_fold_performance(X_train, y_train, kfold_splits, best_params, train_indices)\n",
    "    \n",
    "    return model, best_params, metrics, fold_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, params, metrics, fold_results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
