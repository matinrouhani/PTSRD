{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7436918-b603-44d4-b4b7-b3a7c38c24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ===================  Optimizer Functions =====================\n",
    "# Note: optimizer implementation\n",
    "# Sources: https://github.com/thieu1995/mealpy\n",
    "# https://github.com/Valdecy/pyMetaheuristic\n",
    "\n",
    "# =================== CatBoost & Data Preparation =====================\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load data and prepare train/test splits with scaling.\"\"\"\n",
    "    data = pd.read_excel(file_path)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    \n",
    "    # Apply scaling\n",
    "    scaler_X = PowerTransformer()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        X_scaled, y, data.index, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, train_indices, test_indices, scaler_X\n",
    "\n",
    "def create_objective_function_with_kfold(X_train, y_train, n_splits=5):\n",
    "    \"\"\"Create objective function with K-fold cross-validation for hyperparameter optimization.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    kfold_splits = list(kf.split(X_train))\n",
    "    \n",
    "    def objective_function(params):\n",
    "        depth, learning_rate, l2_leaf_reg, bagging_temperature, random_strength = params\n",
    "        \n",
    "        depth = int(depth)\n",
    "        \n",
    "        model_params = {\n",
    "            'depth': depth,\n",
    "            'learning_rate': learning_rate,\n",
    "            'l2_leaf_reg': l2_leaf_reg,\n",
    "            'bagging_temperature': bagging_temperature,\n",
    "            'random_strength': random_strength,\n",
    "            'verbose': False,\n",
    "            'thread_count': -1\n",
    "        }\n",
    "        \n",
    "        # Perform K-fold cross-validation\n",
    "        fold_rmse_scores = []\n",
    "        for train_idx, val_idx in kfold_splits:\n",
    "            X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            model = CatBoostRegressor(**model_params)\n",
    "            model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val), verbose=False)\n",
    "            \n",
    "            y_pred = model.predict(X_fold_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, y_pred))\n",
    "            fold_rmse_scores.append(rmse)\n",
    "        \n",
    "        return np.mean(fold_rmse_scores)\n",
    "    \n",
    "    return objective_function, kfold_splits\n",
    "\n",
    "def optimize_catboost_hyperparameters(X_train, y_train, iterations=10, population=50, n_splits=5):\n",
    "    \"\"\"Optimize CatBoost hyperparameters using CSA algorithm with K-fold CV.\"\"\"\n",
    "    \n",
    "    # Define parameter bounds for CatBoost\n",
    "    param_bounds = {\n",
    "        'depth': (4, 8),\n",
    "        'learning_rate': (0.05, 0.2),\n",
    "        'l2_leaf_reg': (3, 8),\n",
    "        'bagging_temperature': (0.4, 0.8),\n",
    "        'random_strength': (0.5, 3)\n",
    "    }\n",
    "    \n",
    "    param_names = ['depth', 'learning_rate', 'l2_leaf_reg', 'bagging_temperature', 'random_strength']\n",
    "    \n",
    "    lb = [param_bounds[name][0] for name in param_names]\n",
    "    ub = [param_bounds[name][1] for name in param_names]\n",
    "    \n",
    "    # Create objective function with K-fold CV\n",
    "    objective_function, kfold_splits = create_objective_function_with_kfold(X_train, y_train, n_splits)\n",
    "    \n",
    "    # Create problem bounds using Mealpy's FloatVar\n",
    "    bounds = FloatVar(lb=lb, ub=ub, name=\"hyperparams\")\n",
    "    problem_dict = {\n",
    "        \"bounds\": bounds,\n",
    "        \"minmax\": \"min\",\n",
    "        \"obj_func\": objective_function\n",
    "    }\n",
    "    \n",
    "    # Run CSA optimization\n",
    "    optimizer = OriginalCircleSA(epoch=iterations, pop_size=population)\n",
    "    g_best = optimizer.solve(problem_dict)\n",
    "    best_solution = g_best.solution\n",
    "    best_fitness = g_best.target.fitness\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    best_params = {\n",
    "        'depth': int(best_solution[0]),\n",
    "        'learning_rate': best_solution[1],\n",
    "        'l2_leaf_reg': best_solution[2],\n",
    "        'bagging_temperature': best_solution[3],\n",
    "        'random_strength': best_solution[4],\n",
    "        'verbose': False,\n",
    "        'thread_count': -1\n",
    "    }\n",
    "    \n",
    "    return best_params, best_fitness, kfold_splits\n",
    "\n",
    "def evaluate_fold_performance(X_train, y_train, kfold_splits, best_params, train_indices):\n",
    "    \"\"\"Evaluate model performance on individual K-fold splits.\"\"\"\n",
    "    fold_results = {}\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kfold_splits):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Train model on this fold\n",
    "        fold_model = CatBoostRegressor(**best_params)\n",
    "        fold_model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val), verbose=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        fold_train_pred = fold_model.predict(X_fold_train)\n",
    "        fold_val_pred = fold_model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_results[f'fold_{fold_idx + 1}'] = {\n",
    "            'train_indices': train_indices[train_idx],\n",
    "            'val_indices': train_indices[val_idx],\n",
    "            'fold_train_pred': fold_train_pred,\n",
    "            'fold_val_pred': fold_val_pred,\n",
    "            'metrics': {\n",
    "                'train_r2': r2_score(y_fold_train, fold_train_pred),\n",
    "                'train_rmse': np.sqrt(mean_squared_error(y_fold_train, fold_train_pred)),\n",
    "                'train_mae': mean_absolute_error(y_fold_train, fold_train_pred),\n",
    "                'val_r2': r2_score(y_fold_val, fold_val_pred),\n",
    "                'val_rmse': np.sqrt(mean_squared_error(y_fold_val, fold_val_pred)),\n",
    "                'val_mae': mean_absolute_error(y_fold_val, fold_val_pred)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, params):\n",
    "    \"\"\"Train CatBoost model with optimized parameters and return metrics.\"\"\"\n",
    "    \n",
    "    # Train the model\n",
    "    catboost_model = CatBoostRegressor(**params)\n",
    "    catboost_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = catboost_model.predict(X_train)\n",
    "    test_predictions = catboost_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'train_r2': r2_score(y_train, train_predictions),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, train_predictions)),\n",
    "        'train_mae': mean_absolute_error(y_train, train_predictions),\n",
    "        'test_r2': r2_score(y_test, test_predictions),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, test_predictions)),\n",
    "        'test_mae': mean_absolute_error(y_test, test_predictions)\n",
    "    }\n",
    "    \n",
    "    return catboost_model, metrics\n",
    "\n",
    "def main(file_path=\"P03.xlsx\", iterations=10, population=50, n_splits=5):\n",
    "    \"\"\"Main function to run CatBoost optimization with CSA and K-fold CV.\"\"\"\n",
    "    \n",
    "    # Load and prepare data\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices, scaler = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Optimize hyperparameters with K-fold CV\n",
    "    best_params, best_fitness, kfold_splits = optimize_catboost_hyperparameters(\n",
    "        X_train, y_train, iterations, population, n_splits\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate final model\n",
    "    model, metrics = train_and_evaluate_model(X_train, X_test, y_train, y_test, best_params)\n",
    "    \n",
    "    # Evaluate individual fold performance\n",
    "    fold_results = evaluate_fold_performance(X_train, y_train, kfold_splits, best_params, train_indices)\n",
    "    \n",
    "    return model, best_params, metrics, fold_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, params, metrics, fold_results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
