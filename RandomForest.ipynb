{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdab9ab-a2da-4a41-9dd8-b288837514a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ===================  Optimizer Functions =====================\n",
    "# Note: optimizer implementation\n",
    "# Sources: https://github.com/thieu1995/mealpy\n",
    "# https://github.com/Valdecy/pyMetaheuristic\n",
    "\n",
    "# =================== Random Forest & Data Preparation =====================\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load data and prepare train/test splits with scaling.\"\"\"\n",
    "    data = pd.read_excel(file_path)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    \n",
    "    # Apply scaling\n",
    "    scaler_X = PowerTransformer()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        X_scaled, y, data.index, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, train_indices, test_indices, scaler_X\n",
    "\n",
    "def create_objective_function_with_kfold(X_train, y_train, n_splits=5):\n",
    "    \"\"\"Create objective function with K-fold cross-validation for hyperparameter optimization.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    kfold_splits = list(kf.split(X_train))\n",
    "    \n",
    "    def objective_function(params):\n",
    "        n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap, max_samples = params\n",
    "        \n",
    "        # Convert parameters to appropriate types\n",
    "        n_estimators = int(n_estimators)\n",
    "        max_depth = int(max_depth) if max_depth > 0 else None\n",
    "        min_samples_split = int(min_samples_split)\n",
    "        min_samples_leaf = int(min_samples_leaf)\n",
    "        bootstrap = bool(round(bootstrap))\n",
    "        \n",
    "        model_params = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'max_features': max_features,\n",
    "            'bootstrap': bootstrap,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # Only add max_samples if bootstrap is True\n",
    "        if bootstrap:\n",
    "            model_params['max_samples'] = max_samples\n",
    "        \n",
    "        # Perform K-fold cross-validation\n",
    "        fold_rmse_scores = []\n",
    "        for train_idx, val_idx in kfold_splits:\n",
    "            X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            model = RandomForestRegressor(**model_params)\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            y_pred = model.predict(X_fold_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, y_pred))\n",
    "            fold_rmse_scores.append(rmse)\n",
    "        \n",
    "        return np.mean(fold_rmse_scores)\n",
    "    \n",
    "    return objective_function, kfold_splits\n",
    "\n",
    "def optimize_rf_hyperparameters(X_train, y_train, iterations=10, population=50, n_splits=5):\n",
    "    \"\"\"Optimize Random Forest hyperparameters using CSA algorithm with K-fold CV.\"\"\"\n",
    "    \n",
    "    # Define parameter bounds for Random Forest\n",
    "    param_bounds = {\n",
    "        'n_estimators': (100, 500),\n",
    "        'max_depth': (5, 30),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 10),\n",
    "        'max_features': (0.1, 1.0),\n",
    "        'bootstrap': (0, 1),\n",
    "        'max_samples': (0.5, 1.0)\n",
    "    }\n",
    "    \n",
    "    param_names = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', \n",
    "                   'max_features', 'bootstrap', 'max_samples']\n",
    "    \n",
    "    lb = [param_bounds[name][0] for name in param_names]\n",
    "    ub = [param_bounds[name][1] for name in param_names]\n",
    "    \n",
    "    # Create objective function with K-fold CV\n",
    "    objective_function, kfold_splits = create_objective_function_with_kfold(X_train, y_train, n_splits)\n",
    "    \n",
    "    # Create problem bounds using Mealpy's FloatVar\n",
    "    bounds = FloatVar(lb=lb, ub=ub, name=\"hyperparams\")\n",
    "    problem_dict = {\n",
    "        \"bounds\": bounds,\n",
    "        \"minmax\": \"min\",\n",
    "        \"obj_func\": objective_function\n",
    "    }\n",
    "    \n",
    "    # Run CSA optimization\n",
    "    optimizer = OriginalCircleSA(epoch=iterations, pop_size=population)\n",
    "    g_best = optimizer.solve(problem_dict)\n",
    "    best_solution = g_best.solution\n",
    "    best_fitness = g_best.target.fitness\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    best_params = {\n",
    "        'n_estimators': int(best_solution[0]),\n",
    "        'max_depth': int(best_solution[1]) if best_solution[1] > 0 else None,\n",
    "        'min_samples_split': int(best_solution[2]),\n",
    "        'min_samples_leaf': int(best_solution[3]),\n",
    "        'max_features': best_solution[4],\n",
    "        'bootstrap': bool(round(best_solution[5])),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    # Only add max_samples if bootstrap is True\n",
    "    if best_params['bootstrap']:\n",
    "        best_params['max_samples'] = best_solution[6]\n",
    "    \n",
    "    return best_params, best_fitness, kfold_splits\n",
    "\n",
    "def evaluate_fold_performance(X_train, y_train, kfold_splits, best_params, train_indices):\n",
    "    \"\"\"Evaluate model performance on individual K-fold splits.\"\"\"\n",
    "    fold_results = {}\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kfold_splits):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Train model on this fold\n",
    "        fold_model = RandomForestRegressor(**best_params)\n",
    "        fold_model.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        fold_train_pred = fold_model.predict(X_fold_train)\n",
    "        fold_val_pred = fold_model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_results[f'fold_{fold_idx + 1}'] = {\n",
    "            'train_indices': train_indices[train_idx],\n",
    "            'val_indices': train_indices[val_idx],\n",
    "            'fold_train_pred': fold_train_pred,\n",
    "            'fold_val_pred': fold_val_pred,\n",
    "            'metrics': {\n",
    "                'train_r2': r2_score(y_fold_train, fold_train_pred),\n",
    "                'train_rmse': np.sqrt(mean_squared_error(y_fold_train, fold_train_pred)),\n",
    "                'train_mae': mean_absolute_error(y_fold_train, fold_train_pred),\n",
    "                'val_r2': r2_score(y_fold_val, fold_val_pred),\n",
    "                'val_rmse': np.sqrt(mean_squared_error(y_fold_val, fold_val_pred)),\n",
    "                'val_mae': mean_absolute_error(y_fold_val, fold_val_pred)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, params):\n",
    "    \"\"\"Train Random Forest model with optimized parameters and return metrics.\"\"\"\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model = RandomForestRegressor(**params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = rf_model.predict(X_train)\n",
    "    test_predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'train_r2': r2_score(y_train, train_predictions),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, train_predictions)),\n",
    "        'train_mae': mean_absolute_error(y_train, train_predictions),\n",
    "        'test_r2': r2_score(y_test, test_predictions),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, test_predictions)),\n",
    "        'test_mae': mean_absolute_error(y_test, test_predictions)\n",
    "    }\n",
    "    \n",
    "    return rf_model, metrics\n",
    "\n",
    "def main(file_path=\"P03.xlsx\", iterations=10, population=50, n_splits=5):\n",
    "    \"\"\"Main function to run Random Forest optimization with CSA and K-fold CV.\"\"\"\n",
    "    \n",
    "    # Load and prepare data\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices, scaler = load_and_prepare_data(file_path)\n",
    "    \n",
    "    # Optimize hyperparameters with K-fold CV\n",
    "    best_params, best_fitness, kfold_splits = optimize_rf_hyperparameters(\n",
    "        X_train, y_train, iterations, population, n_splits\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate final model\n",
    "    model, metrics = train_and_evaluate_model(X_train, X_test, y_train, y_test, best_params)\n",
    "    \n",
    "    # Evaluate individual fold performance\n",
    "    fold_results = evaluate_fold_performance(X_train, y_train, kfold_splits, best_params, train_indices)\n",
    "    \n",
    "    return model, best_params, metrics, fold_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, params, metrics, fold_results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
